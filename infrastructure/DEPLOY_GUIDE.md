# ğŸ¯ Guide de DÃ©ploiement - Infrastructure CDK

## âœ… Ce qui a Ã©tÃ© crÃ©Ã©

Infrastructure complÃ¨te AWS CDK (Infrastructure as Code) pour gÃ©nÃ©ration vidÃ©o scalable:

```
infrastructure/
â”œâ”€â”€ app.py                          # Application CDK principale
â”œâ”€â”€ stacks/
â”‚   â””â”€â”€ video_processing_stack.py   # Stack complet (ECR, SQS, ECS, Autoscaling)
â”œâ”€â”€ cdk.json                        # Configuration CDK
â”œâ”€â”€ requirements.txt                # DÃ©pendances Python
â”œâ”€â”€ deploy.sh                       # Script de dÃ©ploiement simplifiÃ©
â””â”€â”€ README.md                       # Documentation complÃ¨te
```

## ğŸ¯ Ce que Ã§a dÃ©ploie

- **ECR Repository** - Stockage image Docker FFmpeg avec polices custom
- **SQS Queue** - File de jobs vidÃ©o + Dead Letter Queue
- **ECS Cluster** - Cluster Fargate pour workers
- **ECS Service** - 10 workers toujours actifs (warm pool configurable)
- **Autoscaling** - Scale automatique basÃ© sur SQS (max 50 workers)
- **IAM Roles** - Permissions minimales (S3 + SQS seulement)
- **CloudWatch** - Logs + Dashboard de monitoring

## ğŸš€ Ã‰tapes de dÃ©ploiement

### âš ï¸ AVANT DE COMMENCER

**Tu dois faire Ã§a dans AWS Console (une seule fois):**

1. **Aller sur AWS IAM**: https://console.aws.amazon.com/iam/

2. **Trouver le user** `hospup-s3-uploader`

3. **Ajouter ces permissions** (cliquer "Add permissions" â†’ "Attach policies directly"):
   - âœ… `AmazonECS_FullAccess`
   - âœ… `AmazonEC2ContainerRegistryFullAccess`
   - âœ… `AmazonSQSFullAccess`
   - âœ… `CloudWatchFullAccess`
   - âœ… `IAMFullAccess` (ou crÃ©er policy custom - voir PERMISSIONS.md)
   - âœ… `ApplicationAutoScalingFullAccess`

4. **Cliquer "Add permissions"** puis **"Attach policies"**

**Pourquoi c'est nÃ©cessaire ?**
- Le user actuel n'a que S3 access
- CDK a besoin de crÃ©er ECR, ECS, SQS, IAM roles, etc.
- AprÃ¨s dÃ©ploiement, les workers ECS auront des permissions minimales (S3 + SQS seulement)

---

### 1ï¸âƒ£ DÃ©ployer l'infrastructure CDK

```bash
cd /Users/doriandubord/Desktop/hospup-project/hospup-backend/infrastructure

# DÃ©ployer avec defaults (10 workers, max 50)
./deploy.sh

# OU avec custom config
WARM_POOL_SIZE=20 MAX_WORKERS=100 ./deploy.sh
```

**Ce qui se passe:**
- âœ… Bootstrap CDK (si premiÃ¨re fois)
- âœ… CrÃ©e ECR, SQS, ECS Cluster, Service
- âœ… Configure autoscaling
- âœ… CrÃ©e dashboard CloudWatch
- âœ… GÃ©nÃ¨re `outputs.json` avec URLs importantes

**DurÃ©e:** ~5-10 minutes

---

### 2ï¸âƒ£ Build et push l'image Docker

```bash
cd /Users/doriandubord/Desktop/hospup-project/hospup-backend/aws-ecs-ffmpeg

# RÃ©cupÃ©rer ECR URI (du deploy prÃ©cÃ©dent)
ECR_URI=$(cat ../infrastructure/outputs.json | python3 -c "import sys, json; print(json.load(sys.stdin)['HospupVideoProcessing']['ECRRepositoryURI'])")

# Build image
docker build -t hospup-ffmpeg-worker .

# Tag
docker tag hospup-ffmpeg-worker:latest $ECR_URI:latest

# Login ECR
aws ecr get-login-password --region eu-west-1 | docker login --username AWS --password-stdin $ECR_URI

# Push
docker push $ECR_URI:latest
```

**DurÃ©e:** ~5-10 minutes (selon connexion)

---

### 3ï¸âƒ£ DÃ©marrer les workers

```bash
# Forcer redÃ©ploiement workers avec nouvelle image
aws ecs update-service \
  --cluster hospup-video-processing \
  --service ffmpeg-worker-service \
  --force-new-deployment \
  --region eu-west-1
```

**DurÃ©e:** ~2-3 minutes

---

### 4ï¸âƒ£ Configurer Railway

```bash
# RÃ©cupÃ©rer SQS URL
cat /Users/doriandubord/Desktop/hospup-project/hospup-backend/infrastructure/outputs.json | python3 -c "import sys, json; print(json.load(sys.stdin)['HospupVideoProcessing']['SQSQueueURL'])"
```

**Ajouter dans Railway** (Environment Variables):
```
SQS_QUEUE_URL=https://sqs.eu-west-1.amazonaws.com/412655955859/hospup-video-jobs
```

---

### 5ï¸âƒ£ Push backend vers Railway

```bash
cd /Users/doriandubord/Desktop/hospup-project/hospup-backend

git add .
git commit -m "ğŸš€ FEAT: ECS Fargate FFmpeg with warm pool (10 workers)"
git push
```

**Railway va auto-dÃ©ployer** avec la nouvelle config SQS.

---

### 6ï¸âƒ£ Tester !

```
https://hospup-frontend-2-kappa.vercel.app/dashboard/video-debug
```

**Cliquer "Test Video Generation"**

**RÃ©sultat attendu:**
- Backend envoie job Ã  SQS âœ…
- Worker ECS (dÃ©jÃ  actif) rÃ©cupÃ¨re instantanÃ©ment (0s cold start) âœ…
- FFmpeg gÃ©nÃ¨re vidÃ©o avec 4 polices custom diffÃ©rentes âœ…
- Webhook callback vers Railway âœ…
- VidÃ©o disponible dans content library âœ…

---

## ğŸ“Š Monitoring

### Dashboard CloudWatch

URL dans outputs ou:
```
https://eu-west-1.console.aws.amazon.com/cloudwatch/home?region=eu-west-1#dashboards:name=HospupVideoProcessing
```

### Logs en temps rÃ©el

```bash
aws logs tail /ecs/hospup-ffmpeg-worker --follow --region eu-west-1
```

### Status du service

```bash
aws ecs describe-services \
  --cluster hospup-video-processing \
  --services ffmpeg-worker-service \
  --region eu-west-1 \
  --query 'services[0].[runningCount,desiredCount,pendingCount]'
```

---

## ğŸšï¸ Ajuster le warm pool

### Augmenter Ã  20 workers

```bash
cd /Users/doriandubord/Desktop/hospup-project/hospup-backend/infrastructure

WARM_POOL_SIZE=20 MAX_WORKERS=100 ./deploy.sh
```

CDK va faire un **rolling update** sans downtime.

### RÃ©duire Ã  5 workers

```bash
WARM_POOL_SIZE=5 MAX_WORKERS=50 ./deploy.sh
```

---

## ğŸ’° CoÃ»ts

| Config | CoÃ»t/mois | Cold start |
|--------|-----------|-----------|
| 10 workers | ~$300 | 0s pour 10 users |
| 20 workers | ~$600 | 0s pour 20 users |
| 50 workers | ~$1500 | 0s pour 50 users |

**vs MediaConvert:** $1500-3000/mois pour mÃªme volume

---

## ğŸ”§ Troubleshooting

### Permission denied lors du deploy

â†’ Ajouter permissions au user AWS (voir Ã©tape "AVANT DE COMMENCER")

### Bootstrap failed

```bash
# Bootstrap manuellement
cd infrastructure
npx cdk bootstrap aws://412655955859/eu-west-1
```

### Image push failed

```bash
# Re-login ECR
aws ecr get-login-password --region eu-west-1 | docker login --username AWS --password-stdin 412655955859.dkr.ecr.eu-west-1.amazonaws.com
```

### Workers ne dÃ©marrent pas

```bash
# Voir logs
aws logs tail /ecs/hospup-ffmpeg-worker --since 10m --region eu-west-1

# VÃ©rifier task definition
aws ecs describe-task-definition --task-definition hospup-ffmpeg-worker --region eu-west-1
```

---

## ğŸ—‘ï¸ DÃ©truire tout

```bash
cd /Users/doriandubord/Desktop/hospup-project/hospup-backend/infrastructure

npx cdk destroy
```

**ATTENTION:** Ã‡a supprime TOUTE l'infrastructure (ECR, SQS, ECS, etc.)

---

## ğŸ“š Documentation

- `README.md` - Documentation technique complÃ¨te
- `../aws-ecs-ffmpeg/PERMISSIONS.md` - DÃ©tails permissions AWS
- `../aws-ecs-ffmpeg/STRATEGY.md` - StratÃ©gie warm pool et coÃ»ts

---

## âœ… Checklist finale

- [ ] Permissions AWS ajoutÃ©es au user
- [ ] CDK dÃ©ployÃ© (`./deploy.sh`)
- [ ] Image Docker pushÃ©e vers ECR
- [ ] Workers ECS dÃ©marrÃ©s
- [ ] SQS_QUEUE_URL ajoutÃ© dans Railway
- [ ] Backend pushÃ© vers Railway
- [ ] Test sur video-debug rÃ©ussi âœ¨

**Une fois tout âœ…, tu as une infrastructure production-ready avec:**
- ğŸ”¥ 10 workers toujours actifs (0s cold start)
- ğŸ“ˆ Autoscaling jusqu'Ã  50 workers
- ğŸ¨ Polices custom multiples (Roboto, Montserrat, Playfair, Open Sans)
- ğŸ’° 2-3x moins cher que MediaConvert
- ğŸ“Š Monitoring CloudWatch complet
- ğŸ”§ Facile Ã  modifier (Infrastructure as Code)
